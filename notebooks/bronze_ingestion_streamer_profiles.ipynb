{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2aee5e79-78d5-4262-8386-3981dc90eaa0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Workspace/Users/laugur1508@gmail.com/twitch_data_pipeline/notebooks')\n",
    "import dlt\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import current_timestamp, to_timestamp, concat, col, lit\n",
    "import logging\n",
    "import json\n",
    "from utils.auth import get_access_token, twitch_api_request\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType, TimestampType\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "empty_schema = StructType([\n",
    "            StructField(\"id\", StringType(), True),\n",
    "            StructField(\"login\", StringType(), True),\n",
    "            StructField(\"display_name\", StringType(), True),\n",
    "            StructField(\"data_collection_time\", TimestampType(), True),\n",
    "            StructField(\"collection_date\", StringType(), True)\n",
    "        ])\n",
    "\n",
    "def get_streamers_profile_data(streamers, client_id, access_token):\n",
    "    users_url = \"https://api.twitch.tv/helix/users\"\n",
    "    batch_size = 100\n",
    "    all_users = []\n",
    "\n",
    "    for i in range(0, len(streamers), batch_size):\n",
    "        batch = streamers[i:i + batch_size]\n",
    "        params = [(\"login\", s) for s in batch]\n",
    "        try:\n",
    "            users = twitch_api_request(users_url, client_id, access_token, params=params)\n",
    "            temp = users.get(\"data\", [])\n",
    "            all_users.extend(temp)\n",
    "            logger.info(f\"User batch {i//batch_size + 1}: Found {len(temp)} users\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"User batch {i//batch_size + 1} failed: {e}\")\n",
    "            continue\n",
    "\n",
    "    return all_users\n",
    "\n",
    "def get_streamers_followers_data(user_ids, client_id, access_token):\n",
    "    followers_url = \"https://api.twitch.tv/helix/channels/followers\"\n",
    "    followers_data = []\n",
    "\n",
    "    for user_id in user_ids:\n",
    "        params = {\"broadcaster_id\": user_id}\n",
    "        try:\n",
    "            data = twitch_api_request(followers_url, client_id, access_token, params=params)\n",
    "            followers_count = data.get(\"total\", 0)\n",
    "            followers_data.append({\n",
    "                \"user_id\": user_id,\n",
    "                \"followers_count\": followers_count\n",
    "            })\n",
    "            logger.info(f\"Got followers for {user_id}: {followers_count}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to get followers for {user_id}: {e}\")\n",
    "            followers_data.append({\n",
    "                \"user_id\": user_id,\n",
    "                \"followers_count\": 0\n",
    "            })\n",
    "\n",
    "    return followers_data\n",
    "\n",
    "def get_streamers_channel_info(user_ids, client_id, access_token):\n",
    "    channels_url = \"https://api.twitch.tv/helix/channels\"\n",
    "    batch_size = 20\n",
    "    all_channels = []\n",
    "\n",
    "    for i in range(0, len(user_ids), batch_size):\n",
    "        batch = user_ids[i:i + batch_size]\n",
    "        params = [(\"broadcaster_id\", uid) for uid in batch]\n",
    "        try:\n",
    "            channels = twitch_api_request(channels_url, client_id, access_token, params=params)\n",
    "            temp = channels.get(\"data\", [])\n",
    "            all_channels.extend(temp)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to get channels batch {i//batch_size + 1}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return all_channels\n",
    "\n",
    "def clean_profile_data(users_data, followers_data, channels_data):\n",
    "    if not users_data:\n",
    "        return None\n",
    "    \n",
    "    users_df = pd.DataFrame(users_data)\n",
    "    followers_df = pd.DataFrame(followers_data)\n",
    "    channels_df = pd.DataFrame(channels_data)\n",
    "\n",
    "    merged_df = users_df.merge(followers_df, left_on='id', right_on='user_id', how='left')\n",
    "    if 'user_id' in merged_df.columns:\n",
    "        merged_df = merged_df.drop('user_id', axis=1)\n",
    "    merged_df = merged_df.merge(channels_df, left_on='id', right_on='broadcaster_id', how='left')\n",
    "\n",
    "    final_columns = {\n",
    "        'id': 'user_id',\n",
    "        'login': 'username',\n",
    "        'display_name': 'display_name',\n",
    "        'type': 'user_type',\n",
    "        'broadcaster_type': 'broadcaster_type',\n",
    "        'description': 'description',\n",
    "        'profile_image_url': 'profile_image_url',\n",
    "        'offline_image_url': 'offline_image_url',\n",
    "        'created_at': 'account_created_at',\n",
    "        'followers_count': 'followers_count',\n",
    "        'broadcaster_language': 'broadcaster_language',\n",
    "        'game_id': 'current_game_id',\n",
    "        'game_name': 'current_game_name',\n",
    "        'title': 'current_title',\n",
    "        'delay': 'stream_delay'\n",
    "    }\n",
    "\n",
    "    available_columns = {k: v for k, v in final_columns.items() if k in merged_df.columns}\n",
    "    result_df = merged_df[list(available_columns.keys())].rename(columns=available_columns)\n",
    "\n",
    "    result_df = result_df.fillna({\n",
    "        'followers_count': 0,\n",
    "        'description': '',\n",
    "        'current_game_name': '',\n",
    "        'current_title': '',\n",
    "        'broadcaster_language': 'en'\n",
    "    })\n",
    "\n",
    "    return result_df\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"bronze_streamers\",\n",
    "    comment=\"Bronze layer: Twitch streamers profile data with append-only mode\",\n",
    "    table_properties={\n",
    "        \"delta.autoOptimize.optimizeWrite\": \"true\",\n",
    "        \"delta.autoOptimize.autoCompact\": \"true\",\n",
    "        \"pipelines.autoOptimize.managed\": \"true\"\n",
    "    },\n",
    "    table_type=\"live\"\n",
    ")\n",
    "def bronze_streamers():\n",
    "    \"\"\"\n",
    "    Bronze layer table for Twitch streamers profile data.\n",
    "    Uses append mode to ensure data is not overwritten.\n",
    "    \"\"\"\n",
    "    # Get API credentials\n",
    "    CLIENT_ID = dbutils.secrets.get(scope=\"my-secret\", key=\"CLIENT-ID\")\n",
    "    CLIENT_SECRET = dbutils.secrets.get(scope=\"my-secret\", key=\"CLIENT-SECRET\")\n",
    "    ACCESS_TOKEN = get_access_token(CLIENT_ID, CLIENT_SECRET)\n",
    "    \n",
    "    if not ACCESS_TOKEN:\n",
    "        logger.error(\"Failed to get Twitch access token\")\n",
    "        return spark.createDataFrame([], streamers_schema)\n",
    "\n",
    "    # Load configuration\n",
    "    config_path = \"dbfs:/FileStore/config/top50FrenchStreamer.json\"\n",
    "    config = json.loads(dbutils.fs.head(config_path))\n",
    "    top50FrenchStreamers = config[\"top50FrenchStreamers\"]\n",
    "\n",
    "    # Fetch data from Twitch API\n",
    "    users_data = get_streamers_profile_data(top50FrenchStreamers, CLIENT_ID, ACCESS_TOKEN)\n",
    "\n",
    "    if not users_data:\n",
    "        logger.warning(\"No user data fetched from Twitch API\")\n",
    "        return spark.createDataFrame([], streamers_schema)\n",
    "\n",
    "    # Get additional data\n",
    "    user_ids = [user['id'] for user in users_data]\n",
    "    followers_data = get_streamers_followers_data(user_ids, CLIENT_ID, ACCESS_TOKEN)\n",
    "    channels_data = get_streamers_channel_info(user_ids, CLIENT_ID, ACCESS_TOKEN)\n",
    "\n",
    "    # Clean and process data\n",
    "    cleaned_df = clean_profile_data(users_data, followers_data, channels_data)\n",
    "    if cleaned_df is None or cleaned_df.empty:\n",
    "        logger.warning(\"No cleaned data available after processing\")\n",
    "        return spark.createDataFrame([], streamers_schema)\n",
    "\n",
    "    # Convert to Spark DataFrame\n",
    "    spark_df = spark.createDataFrame(cleaned_df)\n",
    "\n",
    "    # Add metadata columns\n",
    "    spark_df = spark_df.withColumn(\"data_collection_time\", current_timestamp()) \\\n",
    "                       .withColumn(\"collection_date\", current_timestamp().cast(\"date\").cast(\"string\"))\n",
    "\n",
    "    # Add unique identifier to prevent duplicates\n",
    "    # Using user_id + collection_date for daily snapshots of streamer profiles\n",
    "    spark_df = spark_df.withColumn(\"record_id\", \n",
    "                                   concat(col(\"user_id\"),  # assuming 'id' is the user_id field\n",
    "                                         lit(\"_\"), \n",
    "                                         col(\"collection_date\")))\n",
    "\n",
    "    logger.info(f\"Successfully processed {spark_df.count()} streamer records\")\n",
    "    return spark_df"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_ingestion_streamer_profiles",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
